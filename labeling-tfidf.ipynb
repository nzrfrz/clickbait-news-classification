{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bffcf2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "390fde8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_clean</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>title_tokens_sastrawi</th>\n",
       "      <th>content_tokens_sastrawi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kejagung sudah periksa 20 orang lebih terkait ...</td>\n",
       "      <td>kejaksaan agung ri tengah mengusut kasus dugaa...</td>\n",
       "      <td>['jagung', 'periksa', '20', 'orang', 'lebih', ...</td>\n",
       "      <td>['jaksa', 'agung', 'ri', 'tengah', 'usut', 'ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jimly asshiddiqie-mahfud ke istana jelang pela...</td>\n",
       "      <td>sejumlah tokoh merapat ke istana kepresidenan ...</td>\n",
       "      <td>['jimly', 'asshiddiqie', 'mahfud', 'istana', '...</td>\n",
       "      <td>['jumlah', 'tokoh', 'rapat', 'istana', 'presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kejagung limpahkan berkas nadiem makarim dkk k...</td>\n",
       "      <td>kejaksaan agung ri akan melimpahkan berkas per...</td>\n",
       "      <td>['jagung', 'limpah', 'berkas', 'nadiem', 'maka...</td>\n",
       "      <td>['jaksa', 'agung', 'ri', 'limpah', 'berkas', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pramono anung cek lokasi ledakan di sman 72 ja...</td>\n",
       "      <td>gubernur dki jakarta pramono anung tiba di lok...</td>\n",
       "      <td>['pramono', 'anung', 'cek', 'lokasi', 'ledak',...</td>\n",
       "      <td>['gubernur', 'dki', 'jakarta', 'pramono', 'anu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pan akan taati putusan mkd dpr soal uya kuya d...</td>\n",
       "      <td>waketum pan eddy soeparno menanggapi putusan m...</td>\n",
       "      <td>['pan', 'taat', 'putus', 'mkd', 'dpr', 'soal',...</td>\n",
       "      <td>['waketum', 'pan', 'eddy', 'soeparno', 'tangga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title_clean  \\\n",
       "0  kejagung sudah periksa 20 orang lebih terkait ...   \n",
       "1  jimly asshiddiqie-mahfud ke istana jelang pela...   \n",
       "2  kejagung limpahkan berkas nadiem makarim dkk k...   \n",
       "3  pramono anung cek lokasi ledakan di sman 72 ja...   \n",
       "4  pan akan taati putusan mkd dpr soal uya kuya d...   \n",
       "\n",
       "                                       content_clean  \\\n",
       "0  kejaksaan agung ri tengah mengusut kasus dugaa...   \n",
       "1  sejumlah tokoh merapat ke istana kepresidenan ...   \n",
       "2  kejaksaan agung ri akan melimpahkan berkas per...   \n",
       "3  gubernur dki jakarta pramono anung tiba di lok...   \n",
       "4  waketum pan eddy soeparno menanggapi putusan m...   \n",
       "\n",
       "                               title_tokens_sastrawi  \\\n",
       "0  ['jagung', 'periksa', '20', 'orang', 'lebih', ...   \n",
       "1  ['jimly', 'asshiddiqie', 'mahfud', 'istana', '...   \n",
       "2  ['jagung', 'limpah', 'berkas', 'nadiem', 'maka...   \n",
       "3  ['pramono', 'anung', 'cek', 'lokasi', 'ledak',...   \n",
       "4  ['pan', 'taat', 'putus', 'mkd', 'dpr', 'soal',...   \n",
       "\n",
       "                             content_tokens_sastrawi  \n",
       "0  ['jaksa', 'agung', 'ri', 'tengah', 'usut', 'ka...  \n",
       "1  ['jumlah', 'tokoh', 'rapat', 'istana', 'presid...  \n",
       "2  ['jaksa', 'agung', 'ri', 'limpah', 'berkas', '...  \n",
       "3  ['gubernur', 'dki', 'jakarta', 'pramono', 'anu...  \n",
       "4  ['waketum', 'pan', 'eddy', 'soeparno', 'tangga...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load sastrawi tokenized data\n",
    "df = pd.read_csv(\"./text_tokenized_sastrawi.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8821f606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined Title Tokens: \n",
      " 0    jagung periksa 20 orang lebih kait kasus limba...\n",
      "1    jimly asshiddiqie mahfud istana jelang lantik ...\n",
      "2    jagung limpah berkas nadiem makarim dkk jpu pe...\n",
      "3       pramono anung cek lokasi ledak sman 72 jakarta\n",
      "4      pan taat putus mkd dpr soal uya kuya eko patrio\n",
      "Name: title_text, dtype: object\n",
      "\n",
      "\n",
      "Joined Content Tokens: \n",
      " 0    jaksa agung ri tengah usut kasus duga korupsi ...\n",
      "1    jumlah tokoh rapat istana presiden jakarta jel...\n",
      "2    jaksa agung ri limpah berkas perkara sangka ka...\n",
      "3    gubernur dki jakarta pramono anung tiba lokasi...\n",
      "4    waketum pan eddy soeparno tanggap putus mahkam...\n",
      "Name: content_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Join tokens back to space-separated strings\n",
    "df[\"title_text\"] = df[\"title_tokens_sastrawi\"].astype(str).str.strip(\"[]\").str.replace(\",\", \"\").str.replace(\"'\", \"\")\n",
    "df[\"content_text\"] = df[\"content_tokens_sastrawi\"].astype(str).str.strip(\"[]\").str.replace(\",\", \"\").str.replace(\"'\", \"\")\n",
    "\n",
    "print(\"Joined Title Tokens: \\n\", df[\"title_text\"][:5])\n",
    "print(\"\\n\")\n",
    "print(\"Joined Content Tokens: \\n\", df[\"content_text\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7ca949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine sim 5 first row: \n",
      " 0    0.243354\n",
      "1    0.397082\n",
      "2    0.478500\n",
      "3    0.577085\n",
      "4    0.696648\n",
      "Name: cosine_similarity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fit TF-IDF on combined corpus for consistent vocabulary\n",
    "corpus = pd.concat([df[\"title_text\"], df[\"content_text\"]], axis=0)\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(corpus)\n",
    "\n",
    "# Split tfidf vectors back into title & content matrices\n",
    "n = len(df)\n",
    "title_vecs = tfidf_matrix[:n]\n",
    "content_vecs = tfidf_matrix[n:]\n",
    "# print(title_vecs)\n",
    "\n",
    "# Cosine similarity title vs content\n",
    "cos_sim = cosine_similarity(title_vecs, content_vecs).diagonal()\n",
    "df[\"cosine_similarity\"] = cos_sim\n",
    "\n",
    "print(\"cosine sim 5 first row: \\n\", df[\"cosine_similarity\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6efdc86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_overlap first row: \n",
      " 0    0.888889\n",
      "1    0.888889\n",
      "2    0.666667\n",
      "3    0.750000\n",
      "4    0.800000\n",
      "Name: token_overlap, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Token overlap (Jaccard-like on sets)\n",
    "def token_overlap(row):\n",
    "  t = set(str(row[\"title_tokens_sastrawi\"]).strip(\"[]\").replace(\"'\",\"\").split())\n",
    "  c = set(str(row[\"content_tokens_sastrawi\"]).strip(\"[]\").replace(\"'\",\"\").split())\n",
    "  if not t:\n",
    "    return 0.0\n",
    "  return len(t & c) / len(t)\n",
    "\n",
    "df[\"token_overlap\"] = df.apply(token_overlap, axis=1)\n",
    "\n",
    "print(\"token_overlap first row: \\n\", df[\"token_overlap\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3488c16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_overlap first row: \n",
      " 0.7233766233766226\n"
     ]
    }
   ],
   "source": [
    "# Determine moderate thresholds from data distribution (quantile-based)\n",
    "cos_th = df[\"cosine_similarity\"].quantile(0.3)  # lower 30%\n",
    "ov_th = df[\"token_overlap\"].quantile(0.3)\n",
    "\n",
    "print(\"token_overlap first row: \\n\", ov_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bebf575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto label: clickbait if both similarity & overlap low\n",
    "df[\"is_clickbait_auto\"] = ((df[\"cosine_similarity\"] < cos_th) & (df[\"token_overlap\"] < ov_th)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f2d54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full CSV\n",
    "# csv_path = \"./text_with_similarity_labels.csv\"\n",
    "# df.to_csv(csv_path, index=False)\n",
    "\n",
    "# # Save 10 random samples to JSON\n",
    "# json_sample_path = \"./text_with_similarity_labels.jsonl\"\n",
    "# df.sample(10, random_state=42).to_json(json_sample_path, orient=\"records\", lines=True, force_ascii=False)\n",
    "\n",
    "# (csv_path, json_sample_path, df[[\"cosine_similarity\",\"token_overlap\",\"is_clickbait_auto\"]].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
