{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef991ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b63fbd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_clean</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>title_tokens_sastrawi</th>\n",
       "      <th>content_tokens_sastrawi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kejagung sudah periksa 20 orang lebih terkait ...</td>\n",
       "      <td>kejaksaan agung ri tengah mengusut kasus dugaa...</td>\n",
       "      <td>['jagung', 'periksa', '20', 'orang', 'lebih', ...</td>\n",
       "      <td>['jaksa', 'agung', 'ri', 'tengah', 'usut', 'ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jimly asshiddiqie-mahfud ke istana jelang pela...</td>\n",
       "      <td>sejumlah tokoh merapat ke istana kepresidenan ...</td>\n",
       "      <td>['jimly', 'asshiddiqie', 'mahfud', 'istana', '...</td>\n",
       "      <td>['jumlah', 'tokoh', 'rapat', 'istana', 'presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kejagung limpahkan berkas nadiem makarim dkk k...</td>\n",
       "      <td>kejaksaan agung ri akan melimpahkan berkas per...</td>\n",
       "      <td>['jagung', 'limpah', 'berkas', 'nadiem', 'maka...</td>\n",
       "      <td>['jaksa', 'agung', 'ri', 'limpah', 'berkas', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pramono anung cek lokasi ledakan di sman 72 ja...</td>\n",
       "      <td>gubernur dki jakarta pramono anung tiba di lok...</td>\n",
       "      <td>['pramono', 'anung', 'cek', 'lokasi', 'ledak',...</td>\n",
       "      <td>['gubernur', 'dki', 'jakarta', 'pramono', 'anu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pan akan taati putusan mkd dpr soal uya kuya d...</td>\n",
       "      <td>waketum pan eddy soeparno menanggapi putusan m...</td>\n",
       "      <td>['pan', 'taat', 'putus', 'mkd', 'dpr', 'soal',...</td>\n",
       "      <td>['waketum', 'pan', 'eddy', 'soeparno', 'tangga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title_clean  \\\n",
       "0  kejagung sudah periksa 20 orang lebih terkait ...   \n",
       "1  jimly asshiddiqie-mahfud ke istana jelang pela...   \n",
       "2  kejagung limpahkan berkas nadiem makarim dkk k...   \n",
       "3  pramono anung cek lokasi ledakan di sman 72 ja...   \n",
       "4  pan akan taati putusan mkd dpr soal uya kuya d...   \n",
       "\n",
       "                                       content_clean  \\\n",
       "0  kejaksaan agung ri tengah mengusut kasus dugaa...   \n",
       "1  sejumlah tokoh merapat ke istana kepresidenan ...   \n",
       "2  kejaksaan agung ri akan melimpahkan berkas per...   \n",
       "3  gubernur dki jakarta pramono anung tiba di lok...   \n",
       "4  waketum pan eddy soeparno menanggapi putusan m...   \n",
       "\n",
       "                               title_tokens_sastrawi  \\\n",
       "0  ['jagung', 'periksa', '20', 'orang', 'lebih', ...   \n",
       "1  ['jimly', 'asshiddiqie', 'mahfud', 'istana', '...   \n",
       "2  ['jagung', 'limpah', 'berkas', 'nadiem', 'maka...   \n",
       "3  ['pramono', 'anung', 'cek', 'lokasi', 'ledak',...   \n",
       "4  ['pan', 'taat', 'putus', 'mkd', 'dpr', 'soal',...   \n",
       "\n",
       "                             content_tokens_sastrawi  \n",
       "0  ['jaksa', 'agung', 'ri', 'tengah', 'usut', 'ka...  \n",
       "1  ['jumlah', 'tokoh', 'rapat', 'istana', 'presid...  \n",
       "2  ['jaksa', 'agung', 'ri', 'limpah', 'berkas', '...  \n",
       "3  ['gubernur', 'dki', 'jakarta', 'pramono', 'anu...  \n",
       "4  ['waketum', 'pan', 'eddy', 'soeparno', 'tangga...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./text_tokenized_sastrawi.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c1cecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name indobenchmark/indobert-base-p2. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "# Load IndoBERT model for sentence embeddings\n",
    "model = SentenceTransformer(\"indobenchmark/indobert-base-p2\")\n",
    "\n",
    "# Function to embed text\n",
    "def embed(text):\n",
    "  return model.encode(text, convert_to_tensor=True, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49411ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 0\n",
      "Processed: 200\n",
      "Processed: 400\n",
      "Processed: 600\n",
      "Processed: 800\n",
      "Processed: 1000\n",
      "Processed: 1200\n",
      "Processed: 1400\n",
      "Processed: 1600\n",
      "Processed: 1800\n",
      "Processed: 2000\n",
      "Processed: 2200\n",
      "Processed: 2400\n",
      "Processed: 2600\n",
      "Processed: 2800\n"
     ]
    }
   ],
   "source": [
    "bert_sims = []\n",
    "\n",
    "# for idx, row in df.iterrows():\n",
    "#   title = row[\"title_clean\"]\n",
    "#   content = row[\"content_clean\"]\n",
    "\n",
    "#   title_emb = embed(title)\n",
    "#   content_emb = embed(content)\n",
    "\n",
    "#   sim = util.cos_sim(title_emb, content_emb).item()\n",
    "#   bert_sims.append(sim)\n",
    "\n",
    "#   if idx % 200 == 0:\n",
    "#     print(f\"Processed: {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a045295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ IndoBERT similarity labeling completed\n",
      "File saved: text_with_bert_labels.csv and sample JSON\n"
     ]
    }
   ],
   "source": [
    "df[\"bert_similarity\"] = bert_sims\n",
    "\n",
    "# Determine threshold (moderate)\n",
    "# threshold = df[\"bert_similarity\"].quantile(0.30)\n",
    "\n",
    "# df[\"is_clickbait_bert\"] = (df[\"bert_similarity\"] < threshold).astype(int)\n",
    "\n",
    "# df.to_csv(\"./text_with_bert_labels.csv\", index=False)\n",
    "# df.sample(10).to_json(\"./text_with_bert_labels_sample.json\", orient=\"records\", lines=True)\n",
    "\n",
    "# print(\"✅ IndoBERT similarity labeling completed\")\n",
    "# print(\"File saved: text_with_bert_labels.csv and sample JSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
